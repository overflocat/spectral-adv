{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "import os\n",
    "from scipy import stats\n",
    "import struct\n",
    "import itertools\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.linalg import eigh\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import scipy as sp\n",
    "import math\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import png\n",
    "import imageio\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets\n",
    "import torch.nn.functional as f\n",
    "\n",
    "#Function for training a model\n",
    "def train_model(model, train_loader, optimizer, loss_criterion, num_epochs=30, num_step_to_display_progress = 250, attack_mode = False, attack_type = 'linf', attack_threshold = 0.01, num_attack_steps = 30, lrate_adv = 0.1):\n",
    "    model.train()\n",
    "    total_step = len(train_loader)\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            # Run the forward pass\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            #print(images.size())\n",
    "            if attack_mode:\n",
    "                attack(model, loss_criterion, images, labels, attack_type, attack_threshold , num_attack_steps , lrate_adv)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "            # Backprop and perform Adam optimisation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track the accuracy\n",
    "            total = labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            acc_list.append(correct / total)\n",
    "\n",
    "            if (i + 1) % num_step_to_display_progress == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                              (correct / total) * 100))\n",
    "\n",
    "\n",
    "#Function for evaluating a model\n",
    "def evaluate_model(model, train_loader, test_loader, loss_criterion = None, attack_mode = False, attack_type = 'linf', attack_threshold = 0.01, num_attack_steps = 30, lrate_adv = 0.1, shape_test = None):\n",
    "    print(\"Starting testing...\")\n",
    "    model.eval()\n",
    "    \n",
    "    adv_data = None;\n",
    "    if shape_test!=None:\n",
    "        adv_data = np.zeros(shape_test)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad=False\n",
    "        \n",
    "    #Train accuracy\n",
    "    if not attack_mode:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Train Accuracy of the model on the {} train images: {} %'.format(total, (correct / total) * 100))\n",
    "\n",
    "    #Test Accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    current_count = 0;\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        if attack_mode:\n",
    "            attack(model, loss_criterion, images, labels, attack_type, attack_threshold , num_attack_steps , lrate_adv)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if shape_test!=None:\n",
    "            adv_data[current_count:current_count+images.size(0),:] = images.to(\"cpu\").numpy();\n",
    "        current_count += images.size(0)\n",
    "\n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, (correct / total) * 100))\n",
    "        \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad=True\n",
    "        \n",
    "    return adv_data\n",
    "                \n",
    "\n",
    "    \n",
    "    \n",
    "def attack(model, loss_criterion, images, labels, attack_type = 'linf', attack_threshold = 0.01, num_attack_steps = 30, lrate_adv = 0.001):\n",
    "    #print(\"attacking\")\n",
    "    for param in model.parameters():\n",
    "        param_requires_grad_original_state = param.requires_grad\n",
    "        param.requires_grad=False\n",
    "    \n",
    "    images_original = images.clone()\n",
    "    for i in range(num_attack_steps):\n",
    "        #print(i)\n",
    "        images.requires_grad = True\n",
    "        outputs = model(images)\n",
    "        loss = loss_criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            if attack_type == 'linf':\n",
    "                ##l-inf attack\n",
    "                \n",
    "                images_grad_step = lrate_adv*torch.sign(images.grad)\n",
    "                #Take grad step\n",
    "                images += images_grad_step\n",
    "                #Project\n",
    "                images += (-images + images_original + torch.clamp(images-images_original, -attack_threshold, attack_threshold))\n",
    "                \n",
    "            else:\n",
    "                ##l2 attack\n",
    "                images_grad = images.grad\n",
    "                num_images = images.size(0)\n",
    "                images_grad_flat_normalized = f.normalize(images_grad.view(num_images,-1),dim=1)\n",
    "                images_grad_step = lrate_adv*images_grad_flat_normalized.view(images.size())\n",
    "\n",
    "                #Take grad step\n",
    "                images += images_grad_step\n",
    "\n",
    "                #Project\n",
    "                total_step = (images-images_original).view(num_images,-1)\n",
    "                total_step_size = total_step.norm(dim=1)\n",
    "                total_step_size = torch.clamp(total_step_size,0,attack_threshold)\n",
    "                normalized_total_step = f.normalize(total_step,dim=1)\n",
    "                total_step = normalized_total_step*total_step_size.view(images.size(0),-1)\n",
    "\n",
    "                images += (-images + images_original + total_step.view(images.size()))\n",
    "                #images = torch.clamp(images,0,1)\n",
    "                ##l-2 attack ends\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = param_requires_grad_original_state\n",
    "    \n",
    "    images.requires_grad = False\n",
    "    \n",
    "\n",
    "#extract laplacian features\n",
    "def extract_laplacian_features(train_data, test_data, num_features = 40, scaled = True, weighted = True, param = 0.025):\n",
    "    x_full = np.concatenate((train_data, test_data))\n",
    "    print(\"Finding distance matrix...\")\n",
    "    dist_mat = pairwise_distances(x_full)\n",
    "\n",
    "    print(\"Creating laplacian matrix...\")\n",
    "    if weighted:\n",
    "        weights_mat = np.exp(-param*np.square(dist_mat))\n",
    "    else:\n",
    "        weights_mat = (dist_mat <= param)\n",
    "    \n",
    "    adj = weights_mat - np.eye(np.size(dist_mat,0))\n",
    "    deg = np.diag(np.sum(adj,1))\n",
    "    \n",
    "    if not scaled:\n",
    "        lap = deg - adj\n",
    "    else:\n",
    "        normalization = np.diag(np.sqrt(1./np.diag(deg)))\n",
    "        lap = np.dot(np.dot(normalization,(deg - adj)),normalization)\n",
    "        \n",
    "    print(\"Finding eigen decomposition...\")\n",
    "    \n",
    "    S, V = eigh(lap, eigvals=(0,num_features))\n",
    "    \n",
    "    train_features = V[0:np.size(train_data,0), 1:1+num_features]\n",
    "    test_features = V[np.size(train_data,0):np.size(x_full,0), 1:1+num_features]\n",
    "    print(\"Done!\")\n",
    "    return train_features, test_features\n",
    "\n",
    "#Function for saving a model\n",
    "def save_model(model, PATH):\n",
    "    print(\"Saving model...\")\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    \n",
    "#Function for loading a saved model\n",
    "def load_model(model, PATH):\n",
    "    print(\"Loading model...\")\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##In this block, we define the architecture of a linear model and a one hiddern layer neural net\n",
    "\n",
    "# Linear net\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc = nn.Linear(num_features, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "    \n",
    "# One-hidder layer neural network\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, 200)\n",
    "        self.fc2 = nn.Linear(200,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = f.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyToTorch:\n",
    "    \"\"\"Given a numpy dataset and corresponding labels, creates a class in torch usable form\"\"\"\n",
    "\n",
    "    def __init__(self, numpy_datapoints, numpy_labels):\n",
    "\n",
    "        self.datapoints = torch.from_numpy(numpy_datapoints).float()\n",
    "        self.labels = torch.from_numpy(numpy_labels).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datapoints)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.datapoints[idx], self.labels[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MNIST data \n",
    "def imshow(img):\n",
    "  plt.imshow(np.reshape(img, (dim,dim)))\n",
    "\n",
    "\n",
    "def read_data(fname_root):\n",
    "  fname_img = fname_root + \"-images-idx3-ubyte\"\n",
    "  fname_lbl = fname_root + \"-labels-idx1-ubyte\"\n",
    "  with open(fname_lbl, 'rb') as flbl:\n",
    "    magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "  with open(fname_img, 'rb') as fimg:\n",
    "    magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows * cols)\n",
    "  return img.astype(np.float32), lbl.astype(int)\n",
    "\n",
    "def preprocess(x): return x/255\n",
    "\n",
    "    \n",
    "x_all, y_all = read_data(\"../../datasets/MNIST/raw/train\")\n",
    "x_test_all, y_test_all = read_data(\"../../datasets/MNIST/raw/t10k\")\n",
    "x_all, x_test_all = map(preprocess, [x_all, x_test_all])\n",
    "n_classes = int(1 + np.max(y_all))\n",
    "print(\"Data loaded\")\n",
    "\n",
    "x, y = x_all[0:10000,:], y_all[0:10000]\n",
    "x_test, y_test = x_test_all[0:1000,:], y_test_all[0:10000]\n",
    "shape_test = np.shape(x_test);\n",
    "\n",
    "dim = 28\n",
    "batch_size = 500\n",
    "\n",
    "trainset = NumpyToTorch(x, y)\n",
    "testset = NumpyToTorch(x_test, y_test)\n",
    "\n",
    "# Data loader\n",
    "train_loader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#Set device to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and evaluating a neural net over MNIST images\n",
    "\n",
    "#Set to false if you want to train the model from scratch\n",
    "PRETRAINED = False\n",
    "\n",
    "#Set to true if you want to save the new trained model\n",
    "SAVENET = False\n",
    "\n",
    "model = NeuralNet(dim**2)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "#Load pretrained model or train the model\n",
    "if PRETRAINED:\n",
    "    load_model(model, 'pretrained_models/MNIST_NN.pth')\n",
    "else:\n",
    "    # Hyperparameters\n",
    "    num_epochs = 30\n",
    "    num_classes = 10\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    #train_model(model, train_loader, optimizer, criterion, num_epochs, 10)\n",
    "    \n",
    "    #For adversarial training:\n",
    "    train_model(model, train_loader, optimizer, criterion, num_epochs, 10, attack_mode = True, attack_type = 'l2', attack_threshold = 2, num_attack_steps = 40, lrate_adv = 0.1)\n",
    "\n",
    "#Evaluate the model\n",
    "#evaluate_model(model, train_loader, test_loader)\n",
    "\n",
    "#Evaluate the model on adversarial test images\n",
    "print(\"Evaluating performance on adversarial test data...\")\n",
    "x_test_adv = evaluate_model(model, train_loader, test_loader, loss_criterion = criterion, attack_mode = True, attack_type = 'l2', attack_threshold = 2, num_attack_steps = 40, lrate_adv = 0.1, shape_test = shape_test)\n",
    "\n",
    "if SAVENET:\n",
    "    save_model(model, 'pretrained_models/MNIST_NN.pth')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extract spectral features\n",
    "x_train_lap_features, x_test_lap_features = extract_laplacian_features(x, x_test_adv, num_features = 40, scaled = True, weighted = True, param = 0.1)\n",
    "#x_train_lap_features, x_test_lap_features = extract_laplacian_features(x, x_test_adv, num_features = 40, scaled = True, weighted = False, param = 9)\n",
    "\n",
    "##Train linear classifier over spectral features\n",
    "train_lap_dataset = NumpyToTorch(x_train_lap_features[:,0:40], y)\n",
    "test_lap_dataset = NumpyToTorch(x_test_lap_features[:,0:40], y_test)\n",
    "\n",
    "# Data loader\n",
    "train_lap_loader = DataLoader(dataset=train_lap_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_lap_loader = DataLoader(dataset=test_lap_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 150\n",
    "num_classes = 10\n",
    "batch_size = 500\n",
    "learning_rate = 1\n",
    "\n",
    "model_linear = LinearNet(40)\n",
    "model_linear = model_linear.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_linear.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(model_linear, train_lap_loader, optimizer, criterion, num_epochs, 10)\n",
    "\n",
    "#Evaluate the model\n",
    "evaluate_model(model_linear, train_lap_loader, test_lap_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
